# Enhanced TEKsystems JobFit Analyzer - Documentation

## ðŸ“‹ Table of Contents
1. [Overview](#overview)
2. [Security Enhancements](#security-enhancements)
3. [Semantic Search Optimization](#semantic-search-optimization)
4. [Installation & Setup](#installation--setup)
5. [Usage Guide](#usage-guide)
6. [Additional Feature Recommendations](#additional-feature-recommendations)
7. [API Reference](#api-reference)

---

## Overview

The Enhanced TEKsystems JobFit Analyzer is a secure, AI-powered recruitment tool that provides:

- **Automatic Security Masking**: PII and client-sensitive information protection
- **Hands-On Experience Validation**: Distinguishes real expertise from resume padding
- **Priority Skills Configuration**: User-configurable targeted evaluation
- **Evidence-Based Skill Matching**: Validates skills with project outcomes and metrics
- **RAG-Powered Analysis**: LangChain + Groq for intelligent document analysis

---

## Security Enhancements

### 1. Resume PII Masking

**What gets masked:**
- âœ… Email addresses â†’ `candidate.email1@example.com`
- âœ… Phone numbers (US & international) â†’ `+1-555-000-0001`
- âœ… Physical addresses â†’ `[Address Redacted]`
- âœ… Social Security Numbers â†’ `***-**-****`
- âœ… Date of Birth â†’ `MM/DD/YYYY`
- âœ… Zip codes (context-aware) â†’ `XXXXX`

**How it works:**
```python
from security_masker import SecurityMasker

masker = SecurityMasker()
result = masker.mask_resume(resume_text)

print(result.masked_text)  # Masked resume
print(result.mask_count)   # Number of items masked
print(result.masking_log)  # Audit log
```

**Security guarantees:**
- Masked data is **never** logged or stored unencrypted
- Original sensitive data is discarded immediately after masking
- Masking is consistent within a document (same email â†’ same placeholder)
- Context-aware masking (avoids false positives on dates, numbers)

### 2. JD Client-Sensitive Masking

**What gets masked:**
- âœ… Client company names â†’ `[Client Company]`
- âœ… Client reference codes â†’ `[CLIENT-REF-REDACTED]`
- âœ… Project codes â†’ `[PROJECT-CODE-REDACTED]`
- âœ… Confidential markers â†’ `[CONFIDENTIAL-REDACTED]`
- âœ… Budget/pricing information â†’ `$[REDACTED]`
- âœ… Internal codes (e.g., PROJ-12345) â†’ `[INTERNAL-CODE-REDACTED]`

**How it works:**
```python
result = masker.mask_jd(
    jd_text,
    known_client_names=["Acme Corp", "TechCo Inc"]
)

print(result.masked_text)
print(result.sensitivity_detected)  # Types of info masked
```

**Masking logic:**
- **Heuristic-based company detection**: Identifies "Acme Technologies LLC" patterns
- **Context-aware budget masking**: Only masks "$150K" near "budget", "cost" keywords
- **Technology exclusions**: Doesn't mask common acronyms (AWS, API, SQL)
- **Custom client lists**: Supports user-specified client names

### 3. Security Audit Logging

**Features:**
- Timestamped masking operations
- Anonymized statistics (no sensitive data in logs)
- Downloadable JSON audit reports
- Real-time masking dashboard

**Audit log example:**
```json
{
  "timestamp": "2026-02-03T12:34:56.789Z",
  "document_type": "resume",
  "mask_count": 7,
  "sensitivity_types": ["email", "phone", "address"],
  "status": "success"
}
```

---

## Semantic Search Optimization

### 1. Hands-On Experience Validation

**Problem:** Traditional resume parsers can't distinguish:
- "Built a Python microservices platform serving 500K users" (HANDS-ON)
- "Python" listed in Skills section (MENTION-ONLY)

**Solution:** Evidence-based validation system that scores skills based on:

#### Experience Depth Levels
| Level | Hands-On Score | Criteria |
|-------|---------------|----------|
| **EXPERT** | 85-100% | Leadership verbs + metrics + outcomes + duration |
| **PROFICIENT** | 70-84% | Core delivery verbs + project context + outcomes |
| **COMPETENT** | 55-69% | Contribution verbs + project mentions |
| **BASIC** | 40-54% | Support verbs + minimal context |
| **MENTIONED_ONLY** | 0-39% | Skills section only, no project evidence |

#### Action Verb Intensity Classification

**Leadership Verbs** (100% intensity):
- led, architected, designed, owned, pioneered, spearheaded

**Core Delivery Verbs** (85% intensity):
- built, implemented, developed, created, deployed, engineered

**Contribution Verbs** (60% intensity):
- contributed, collaborated, worked, participated, enhanced

**Support Verbs** (40% intensity):
- assisted, supported, helped, debugged, tested

**Passive Indicators** (20% intensity):
- familiar with, knowledge of, exposed to, basic understanding

### 2. Metrics & Outcomes Detection

**Detects quantifiable evidence:**
- Percentages: "improved by 40%", "reduced latency 25%"
- Time metrics: "from 2 hours to 15 minutes"
- Scale metrics: "500K daily users", "10M records"
- Money saved: "$150K cost reduction"
- Outcomes: "deployed to production", "launched successfully"

**Example validation:**
```
âŒ "Familiar with Kubernetes"
   â†’ MENTIONED_ONLY (passive verb, no context)

âœ… "Led Kubernetes migration of legacy monolith, 
    reducing infrastructure costs by 30%"
   â†’ EXPERT (leadership verb + metrics + outcome)
```

### 3. Hands-On Scoring Algorithm

**Weighted calculation:**
```python
hands_on_score = (
    semantic_similarity * 0.30 +      # Skill relevance
    action_verb_intensity * 0.30 +    # Verb strength
    metrics_present * 0.15 +          # Quantifiable outcomes
    outcomes_described * 0.10 +       # Results mentioned
    project_duration * 0.10 +         # Experience length
    context_type_bonus * 0.05         # Project vs. Skills section
)
```

**Result:** 0.0-1.0 score indicating true hands-on depth

### 4. Priority Skills Configuration

**User-configurable input:**
```
Priority Skills (one per line or comma-separated):
Python
AWS
Kubernetes
PostgreSQL
```

**Effects:**
- ðŸŽ¯ Priority skills weighted 1.5x in overall scoring
- Missing priority skills flagged as ðŸš¨ CRITICAL
- Weak evidence for priority skills highlighted as âš ï¸
- Results sorted by priority + hands-on score

**Use case:**
> "This role absolutely requires AWS and Kubernetes expertise. 
> Nice-to-haves: React, MongoDB"
> 
> â†’ Configure AWS, Kubernetes as priority
> â†’ System heavily penalizes candidates missing these
> â†’ Candidates with AWS/K8s listed but no project evidence get flagged

---

## Installation & Setup

### Prerequisites
- Python 3.11+
- Groq API key (for LLM)

### Installation

```bash
# Clone repository
git clone <repository-url>
cd recruitment-tool

# Install dependencies
pip install -r requirements.txt --break-system-packages

# Set up environment
echo "GROQ_API_KEY=your_api_key_here" > .env
```

### Requirements.txt
```
streamlit>=1.28.0
langchain>=0.3.0
langchain-community>=0.3.0
langchain-groq>=0.1.0
langchain-text-splitters>=0.0.1
pymupdf>=1.23.0
python-docx>=0.8.11
python-dotenv>=1.0.0
numpy>=1.24.0
pandas>=1.5.0
fastembed>=0.2.0
chromadb>=0.5.0
```

### Running the Application

```bash
streamlit run JD_Resume_Enhanced_Secure.py
```

---

## Usage Guide

### Step 1: Configure Settings (Sidebar)

**LLM Settings:**
- Model: Select Groq model (default: llama-3.3-70b-versatile)
- Temperature: 0.0-1.0 (default: 0.2 for consistency)
- Max tokens: 256-8192 (default: 3000)

**Security Settings:**
- âœ… Enable PII Masking (Resume)
- âœ… Enable Client-Sensitive Masking (JD)
- âœ… Show Masking Details

**Priority Skills:**
```
Python
AWS
Kubernetes
PostgreSQL
```

**Enhanced Semantic Search:**
- Min Hands-On Score: 0.55 (filters out weak evidence)
- Require Metrics/Outcomes: â˜ (optional strict mode)
- Experience Depth Filter: [EXPERT, PROFICIENT, COMPETENT]

### Step 2: Upload Documents

**Job Description:**
1. Click "Upload JD (PDF, DOCX, DOC, TXT)"
2. (Optional) Enter known client names: "Acme Corp, TechCo"
3. View masking summary: "ðŸ”’ Masked 5 sensitive item(s)"
4. Preview masked JD

**Resume:**
1. Click "Upload Resume (PDF, DOCX, DOC, TXT)"
2. View masking summary: "ðŸ”’ Masked 7 sensitive item(s)"
3. Preview masked resume

### Step 3: Run Analysis

**Enhanced Evidence-Based Validation:**
- Click "ðŸŽ¯ Enhanced Evidence-Based Validation"
- View results in "Analysis Results" tab:
  - Overall Fit Score
  - Validated Skills (with hands-on evidence)
  - Weak/Ignored Skills
  - Evidence Details (metrics, verbs, duration)
  - Recommendations

**Other Analyses:**
- Technical Recruiter Analysis
- Domain Expert Analysis
- Technical Manager Analysis
- Technical Questions
- Coding Questions

### Step 4: Review Security Audit

**Security Audit Dashboard:**
- View all masking operations
- Download audit log (JSON)
- Review statistics

---

## Additional Feature Recommendations

### 1. ðŸš€ Batch Candidate Processing

**Problem:** Recruiters screen 50+ resumes per JD manually

**Solution:** Batch upload and ranking
```python
# Upload JD once
# Upload 50 resumes as ZIP
# Get ranked list with scores

Results:
1. Candidate A - 92% fit (5 priority skills validated)
2. Candidate B - 87% fit (4 priority skills validated)
3. Candidate C - 73% fit (3 priority skills, 1 weak)
...
```

**Benefits:**
- â±ï¸ 10x faster than manual screening
- ðŸ“Š Consistent, objective ranking
- ðŸŽ¯ Automatic filtering by fit threshold (e.g., >70%)

**Implementation:**
- Add ZIP upload functionality
- Parallel processing (ThreadPoolExecutor)
- Export ranked list as CSV/Excel

---

### 2. ðŸŽ¤ Interview Question Generator (Lifecycle-Based)

**Problem:** Generic interview questions don't test hands-on experience

**Solution:** Generate questions based on candidate's *actual* project evidence

**Example:**
> **Candidate's Resume:**
> "Optimized PostgreSQL queries, reducing latency by 40%"
> 
> **Generated Question:**
> Q: "You mentioned optimizing PostgreSQL queries that reduced latency by 40%. 
>     Walk me through your approach. What specific optimization techniques did you use? 
>     How did you identify the bottleneck? How did you measure the 40% improvement?"
> 
> **Answer Guide:**
> - Should mention: EXPLAIN ANALYZE, indexing strategies, query planning
> - Red flags: Vague answers, can't explain metrics, no tool knowledge
> - Follow-up: "What would you do differently if you had to do it again?"

**Benefits:**
- ðŸŽ¯ Tests actual claimed experience (harder to fake)
- ðŸ’¡ Reveals depth vs. superficial mentions
- â±ï¸ Saves interviewer prep time

**Implementation:**
- Extend prompt engineering to generate from validated skills
- Include "evidence text" context in question generation
- Add "answer guide" with expected concepts/tools

---

### 3. ðŸ“ˆ Skills Gap Analysis & Learning Path Recommendations

**Problem:** Near-miss candidates (70-80% fit) are rejected instead of developed

**Solution:** Identify skills gap + recommend learning resources

**Example:**
> **Candidate Fit:** 78%
> 
> **Skills Gap Analysis:**
> - âœ… Python (EXPERT) - validated
> - âœ… AWS (PROFICIENT) - validated
> - âš ï¸ Kubernetes (BASIC) - weak evidence, 6 months exp
> - âŒ Terraform - not found
> 
> **Recommended Learning Path:**
> 1. **Kubernetes (Priority):**
>    - Course: "Kubernetes for Developers" (40 hours)
>    - Project: Deploy 3-tier app on K8s with monitoring
>    - Timeline: 2-3 months to reach PROFICIENT
> 
> 2. **Terraform:**
>    - Course: "Infrastructure as Code with Terraform" (20 hours)
>    - Project: Terraform AWS infrastructure for web app
>    - Timeline: 1-2 months to reach COMPETENT
> 
> **Hire-Train-Deploy Recommendation:**
> â†’ Hire as "Junior DevOps Engineer" (current level)
> â†’ 3-month training program (K8s + Terraform)
> â†’ Promote to "DevOps Engineer" after validation

**Benefits:**
- ðŸ’¼ Expands candidate pool (hire for potential, not just fit)
- ðŸ“š Clear development roadmap for hiring managers
- ðŸ”„ Reduces time-to-fill for hard-to-find roles

**Implementation:**
- Map skills to learning resources (course APIs: Udemy, Coursera)
- Estimate learning time based on experience depth gap
- Generate "Hire-Train-Deploy" vs. "Keep Searching" recommendation

---

### 4. ðŸ”— ATS Integration & Auto-Tagging

**Problem:** Recruiters manually copy-paste data into ATS systems

**Solution:** Direct integration with ATS (Greenhouse, Lever, Workday)

**Features:**
- Auto-import JD from ATS
- Auto-upload candidate scores back to ATS
- Tag candidates: `hands-on-python`, `priority-skills-match`, `weak-kubernetes`

**Benefits:**
- â±ï¸ Eliminates double data entry
- ðŸ·ï¸ Searchable tags for future roles
- ðŸ“Š Historical analytics (skill demand trends)

**Implementation:**
- OAuth integration with major ATS platforms
- Webhook support for real-time updates
- Custom field mapping

---

### 5. ðŸ“§ Smart Email Templates (Evidence-Backed)

**Problem:** Recruiters send generic outreach emails

**Solution:** Auto-generate personalized emails citing candidate's actual work

**Example:**
> **Generic:**
> "Hi John, I have an exciting Python developer role. Interested?"
> 
> **Evidence-Backed:**
> "Hi John,
> 
> I came across your work optimizing PostgreSQL queries (40% latency reduction) 
> and your Kubernetes migration project that cut infrastructure costs by 30%.
> 
> We have a Senior DevOps role at [Client] that needs exactly this expertise:
> - Leading K8s migrations for a Fortune 500 client
> - Optimizing database performance at scale (10M+ users)
> 
> Your hands-on experience with AWS, Python, and K8s makes you a strong fit.
> 
> Would you be open to a brief call this week?"

**Benefits:**
- ðŸ“ˆ Higher response rates (personalized, specific)
- ðŸŽ¯ Shows recruiter actually reviewed resume
- â±ï¸ Auto-generated in seconds

**Implementation:**
- Template system with dynamic evidence insertion
- Tone/style customization
- A/B testing for optimization

---

## API Reference

### SecurityMasker

```python
from security_masker import SecurityMasker

masker = SecurityMasker()

# Mask resume PII
resume_result = masker.mask_resume(resume_text)
print(resume_result.masked_text)
print(resume_result.mask_count)
print(resume_result.masking_log)

# Mask JD client-sensitive info
jd_result = masker.mask_jd(
    jd_text,
    known_client_names=["Acme Corp", "TechCo Inc"]
)

# Get human-readable summary
summary = masker.get_masking_summary(jd_result)
```

### EnhancedSemanticSkillMatcher

```python
from enhanced_semantic_matcher import EnhancedSemanticSkillMatcher

matcher = EnhancedSemanticSkillMatcher()

report = matcher.analyze_with_priorities(
    jd_text=jd_text,
    resume_text=resume_text,
    priority_skills=["Python", "AWS", "Kubernetes"]
)

# Access results
print(f"Overall Fit: {report.overall_relevance_score:.0%}")

for skill in report.validated_skills:
    print(f"{skill.skill_name}: {skill.hands_on_score:.0%} hands-on")
    print(f"  Depth: {skill.experience_depth.value}")
    print(f"  Evidence: {skill.reasoning}")
```

### Hands-On Score Calculation

```python
from enhanced_semantic_matcher import EnhancedSkillContextValidator

validator = EnhancedSkillContextValidator()

result = validator.validate_skill_with_depth(
    skill_name="Python",
    resume_sections=sections,
    section_contexts=contexts,
    is_priority=True
)

# Access detailed evidence
for evidence in result.enhanced_evidence:
    print(f"Context: {evidence.context_type.value}")
    print(f"Verb Intensity: {evidence.verb_intensity.value}")
    print(f"Has Metrics: {evidence.has_metrics}")
    print(f"Duration: {evidence.project_duration_months} months")
    print(f"Hands-On Score: {evidence.hands_on_score:.1%}")
```

---

## Security Considerations

### Data Privacy
- âœ… Masked data never logged or persisted
- âœ… Original sensitive data discarded after masking
- âœ… No external API calls with unmasked data
- âœ… Audit logs contain only statistics (no PII)

### False Positive Prevention
- âœ… Context-aware masking (zip codes only near "address")
- âœ… Technology exclusions (AWS, API, SQL not masked)
- âœ… Date vs. DOB disambiguation
- âœ… Consistent placeholders within document

### Compliance
- GDPR-ready (PII masking on upload)
- SOC 2 compatible (audit logging)
- HIPAA-friendly (no health data processed)

---

## Troubleshooting

**Issue: "No masking detected" despite PII present**
- Check if PII masking is enabled in sidebar
- Verify regex patterns match your format (e.g., international phones)
- Review "Show Masking Details" output

**Issue: "Low hands-on scores for clear expertise"**
- Check if resume uses action verbs (built, implemented, led)
- Ensure metrics/outcomes are present ("improved by X%")
- Verify skills appear in Project/Experience sections (not just Skills)

**Issue: "Priority skills not weighted correctly"**
- Confirm priority skills input format (one per line or comma-separated)
- Check skill name exact match (case-insensitive)
- Verify priority skills are in JD skills list

---

## Contributing

### Adding New PII Patterns
```python
# In security_masker.py -> PIIMasker.PATTERNS
PATTERNS = {
    # ... existing patterns ...
    "passport": r'\b[A-Z]{1,2}\d{6,9}\b',  # Add new pattern
}

# Add masking method
def _mask_passport(self, text: str) -> Tuple[str, int]:
    # Implementation
```

### Adding New Action Verbs
```python
# In enhanced_semantic_matcher.py -> EnhancedActionVerbDetector
LEADERSHIP_VERBS = {
    # ... existing verbs ...
    "revolutionized", "transformed",  # Add new verbs
}
```

---

## License

MIT License - See LICENSE file for details

---

## Support

For issues, questions, or feature requests:
- GitHub Issues: <repository-url>/issues
- Email: support@teksystems-jobfit.com
- Documentation: <docs-url>

---

**Last Updated:** February 3, 2026
**Version:** 2.0.0 (Enhanced + Secure Edition)
